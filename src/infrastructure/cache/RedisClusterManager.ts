/**
 * Advanced Redis Cluster Caching Manager
 * High-performance distributed caching with intelligent routing, failover, and monitoring
 */

import { logger, stringUtils } from '@/lib/unjs-utils.js';
import { validationService } from '@/infrastructure/validation/UnJSValidation.js';
import { monitoring } from '@/infrastructure/observability/AdvancedMonitoring.js';
import { z } from 'zod';

export interface CacheNode {
  id: string;
  host: string;
  port: number;
  role: 'master' | 'replica' | 'sentinel';
  status: 'connected' | 'disconnected' | 'error' | 'syncing';
  slots: number[];
  replicas: string[];
  metrics: {
    memory: {
      used: number;
      max: number;
      percentage: number;
    };
    performance: {
      connections: number;
      opsPerSecond: number;
      hitRate: number;
      avgLatency: number;
    };
    replication: {
      lag: number;
      backlog: number;
      syncInProgress: boolean;
    };
  };
  lastPing: Date;
  version: string;
}

export interface CacheCluster {
  id: string;
  name: string;
  nodes: CacheNode[];
  configuration: {
    replicationFactor: number;
    shardCount: number;
    maxMemoryPolicy: 'allkeys-lru' | 'volatile-lru' | 'allkeys-lfu' | 'volatile-lfu' | 'volatile-ttl' | 'noeviction';
    persistence: {
      enabled: boolean;
      type: 'rdb' | 'aof' | 'both';
      schedule: string;
    };
    security: {
      auth: boolean;
      tls: boolean;
      aclEnabled: boolean;
      password?: string;
    };
    networking: {
      timeout: number;
      keepAlive: number;
      maxConnections: number;
      cluster: {
        enabled: boolean;
        nodeTimeout: number;
        requireFullCoverage: boolean;
      };
    };
  };
  status: 'healthy' | 'degraded' | 'offline' | 'maintenance';
  metrics: {
    totalMemory: number;
    usedMemory: number;
    totalConnections: number;
    totalOps: number;
    avgHitRate: number;
    avgLatency: number;
  };
}

export interface CacheOperation {
  id: string;
  type: 'get' | 'set' | 'del' | 'exists' | 'expire' | 'ttl' | 'scan' | 'pipeline' | 'transaction';
  key?: string;
  pattern?: string;
  keys?: string[];
  value?: any;
  ttl?: number;
  options: {
    compress?: boolean;
    serialize?: boolean;
    retries?: number;
    timeout?: number;
    consistency?: 'eventual' | 'strong';
    nodePreference?: 'master' | 'replica' | 'any';
  };
  metadata: {
    tenantId?: string;
    userId?: string;
    source: string;
    timestamp: Date;
    priority: 'low' | 'normal' | 'high' | 'critical';
    tags: string[];
  };
}

export interface CacheEntry {
  key: string;
  value: any;
  ttl: number;
  created: Date;
  accessed: Date;
  hits: number;
  size: number;
  metadata: {
    tenantId?: string;
    type?: string;
    tags: string[];
    compressed: boolean;
    serialized: boolean;
  };
}

export interface CachePolicy {
  id: string;
  name: string;
  pattern: string;
  rules: {
    ttl: {
      default: number;
      min: number;
      max: number;
      sliding?: boolean;
    };
    eviction: {
      policy: 'lru' | 'lfu' | 'ttl' | 'random' | 'custom';
      priority: number;
    };
    storage: {
      compress: boolean;
      serialize: boolean;
      partition?: string;
    };
    replication: {
      factor: number;
      preferredNodes?: string[];
      consistency: 'eventual' | 'strong';
    };
    access: {
      readPreference: 'master' | 'replica' | 'nearest';
      writePolicy: 'write-through' | 'write-back' | 'write-around';
    };
  };
  conditions: {
    keySize?: { min?: number; max?: number };
    valueSize?: { min?: number; max?: number };
    hitRate?: { min?: number };
    accessFrequency?: { min?: number; period?: number };
  };
  enabled: boolean;
  priority: number;
}

export interface CacheStats {
  operations: {
    total: number;
    gets: number;
    sets: number;
    dels: number;
    hits: number;
    misses: number;
    hitRate: number;
  };
  performance: {
    avgLatency: number;
    p95Latency: number;
    p99Latency: number;
    throughput: number;
  };
  memory: {
    used: number;
    available: number;
    fragmentation: number;
    evictions: number;
  };
  connections: {
    active: number;
    idle: number;
    rejected: number;
  };
  replication: {
    syncedNodes: number;
    lagAvg: number;
    lagMax: number;
  };
}

export interface DistributedLock {
  id: string;
  key: string;
  owner: string;
  ttl: number;
  acquired: Date;
  expires: Date;
  renewals: number;
  autoRenew: boolean;
  metadata: Record<string, any>;
}

/**
 * Advanced Redis Cluster Manager for distributed caching
 */
export class RedisClusterManager {
  private clusters: Map<string, CacheCluster> = new Map();
  private nodes: Map<string, CacheNode> = new Map();
  private policies: Map<string, CachePolicy> = new Map();
  private operations: Map<string, CacheOperation> = new Map();
  private locks: Map<string, DistributedLock> = new Map();
  private connectionPools: Map<string, any> = new Map();
  private hashRing: Map<string, string[]> = new Map(); // key -> node mapping
  private stats: CacheStats;
  private circuitBreakers: Map<string, {
    failures: number;
    lastFailure: Date;
    state: 'closed' | 'open' | 'half-open';
  }> = new Map();

  constructor() {
    this.stats = {
      operations: {
        total: 0,
        gets: 0,
        sets: 0,
        dels: 0,
        hits: 0,
        misses: 0,
        hitRate: 0,
      },
      performance: {
        avgLatency: 0,
        p95Latency: 0,
        p99Latency: 0,
        throughput: 0,
      },
      memory: {
        used: 0,
        available: 0,
        fragmentation: 0,
        evictions: 0,
      },
      connections: {
        active: 0,
        idle: 0,
        rejected: 0,
      },
      replication: {
        syncedNodes: 0,
        lagAvg: 0,
        lagMax: 0,
      },
    };

    this.setupValidationSchemas();
    this.setupDefaultCluster();
    this.setupDefaultPolicies();
    this.startHealthMonitoring();
    this.startPerformanceTracking();
    this.startReplicationMonitoring();
    this.startLockMaintenance();
  }

  /**
   * Setup validation schemas
   */
  private setupValidationSchemas(): void {
    const cacheOperationSchema = z.object({
      type: z.enum(['get', 'set', 'del', 'exists', 'expire', 'ttl', 'scan', 'pipeline', 'transaction']),
      key: z.string().optional(),
      pattern: z.string().optional(),
      keys: z.array(z.string()).optional(),
      value: z.any().optional(),
      ttl: z.number().optional(),
      options: z.object({
        compress: z.boolean().optional(),
        serialize: z.boolean().optional(),
        retries: z.number().optional(),
        timeout: z.number().optional(),
        consistency: z.enum(['eventual', 'strong']).optional(),
        nodePreference: z.enum(['master', 'replica', 'any']).optional(),
      }),
      metadata: z.object({
        tenantId: z.string().optional(),
        userId: z.string().optional(),
        source: z.string(),
        priority: z.enum(['low', 'normal', 'high', 'critical']),
        tags: z.array(z.string()),
      }),
    });

    const cachePolicySchema = z.object({
      name: z.string().min(1),
      pattern: z.string().min(1),
      rules: z.object({
        ttl: z.object({
          default: z.number().min(0),
          min: z.number().min(0),
          max: z.number().min(0),
          sliding: z.boolean().optional(),
        }),
        eviction: z.object({
          policy: z.enum(['lru', 'lfu', 'ttl', 'random', 'custom']),
          priority: z.number(),
        }),
        storage: z.object({
          compress: z.boolean(),
          serialize: z.boolean(),
          partition: z.string().optional(),
        }),
      }),
      enabled: z.boolean(),
      priority: z.number(),
    });

    validationService.registerSchema('cacheOperation', cacheOperationSchema);
    validationService.registerSchema('cachePolicy', cachePolicySchema);
  }

  /**
   * Create cache cluster
   */
  createCluster(cluster: Omit<CacheCluster, 'id' | 'status' | 'metrics'>): string {
    const id = stringUtils.random(8);

    const cacheCluster: CacheCluster = {
      id,
      status: 'offline',
      metrics: {
        totalMemory: 0,
        usedMemory: 0,
        totalConnections: 0,
        totalOps: 0,
        avgHitRate: 0,
        avgLatency: 0,
      },
      ...cluster,
    };

    this.clusters.set(id, cacheCluster);

    // Register nodes
    for (const node of cluster.nodes) {
      this.nodes.set(node.id, node);

      // Setup circuit breaker for node
      this.circuitBreakers.set(node.id, {
        failures: 0,
        lastFailure: new Date(0),
        state: 'closed',
      });
    }

    // Initialize hash ring for consistent hashing
    this.updateHashRing(id);

    logger.info('Cache cluster created', {
      clusterId: id,
      name: cluster.name,
      nodeCount: cluster.nodes.length,
      shardCount: cluster.configuration.shardCount,
    });

    monitoring.recordMetric({
      name: 'cache.cluster.created',
      value: 1,
      tags: {
        clusterId: id,
        nodeCount: cluster.nodes.length.toString(),
      },
    });

    return id;
  }

  /**
   * Execute cache operation
   */
  async execute(operation: Omit<CacheOperation, 'id'>): Promise<any> {
    const id = stringUtils.random(12);
    const cacheOperation: CacheOperation = { id, ...operation };

    this.operations.set(id, cacheOperation);

    const spanId = monitoring.startTrace(`cache.operation.${operation.type}`);
    const startTime = Date.now();

    try {
      // Select appropriate cluster and node
      const { cluster, node } = await this.selectNode(cacheOperation);

      // Check circuit breaker
      await this.checkCircuitBreaker(node.id);

      // Apply cache policy
      const policy = this.findApplicablePolicy(cacheOperation);
      if (policy) {
        this.applyPolicy(cacheOperation, policy);
      }

      // Execute operation
      const result = await this.executeOperation(cluster, node, cacheOperation);

      // Update statistics
      const duration = Date.now() - startTime;
      this.updateStats(cacheOperation, duration, true);

      monitoring.finishSpan(spanId, {
        success: true,
        operationId: id,
        operationType: operation.type,
        clusterId: cluster.id,
        nodeId: node.id,
        duration,
      });

      monitoring.recordMetric({
        name: 'cache.operation.success',
        value: 1,
        tags: {
          type: operation.type,
          clusterId: cluster.id,
          nodeId: node.id,
        },
      });

      monitoring.recordMetric({
        name: 'cache.operation.duration',
        value: duration,
        tags: {
          type: operation.type,
          clusterId: cluster.id,
        },
        unit: 'ms',
      });

      return result;

    } catch (error) {
      const duration = Date.now() - startTime;
      this.updateStats(cacheOperation, duration, false);

      monitoring.finishSpan(spanId, {
        success: false,
        operationId: id,
        operationType: operation.type,
        duration,
        error: String(error),
      });

      monitoring.recordMetric({
        name: 'cache.operation.error',
        value: 1,
        tags: {
          type: operation.type,
          error: 'execution_failed',
        },
      });

      logger.error('Cache operation failed', {
        operationId: id,
        type: operation.type,
        key: operation.key,
        error: String(error),
      });

      throw error;
    }
  }

  /**
   * Select optimal node for operation
   */
  private async selectNode(operation: CacheOperation): Promise<{ cluster: CacheCluster; node: CacheNode }> {
    // For now, use the first healthy cluster
    const cluster = Array.from(this.clusters.values()).find(c => c.status === 'healthy');
    if (!cluster) {
      throw new Error('No healthy clusters available');
    }

    let candidateNodes: CacheNode[] = [];

    // Apply node preference
    switch (operation.options.nodePreference) {
      case 'master':
        candidateNodes = cluster.nodes.filter(n => n.role === 'master' && n.status === 'connected');
        break;
      case 'replica':
        candidateNodes = cluster.nodes.filter(n => n.role === 'replica' && n.status === 'connected');
        break;
      default:
        candidateNodes = cluster.nodes.filter(n => n.status === 'connected');
    }

    if (candidateNodes.length === 0) {
      throw new Error('No available nodes for operation');
    }

    // For consistent hashing, use key-based routing
    if (operation.key) {
      const nodeId = this.getNodeForKey(cluster.id, operation.key);
      const node = candidateNodes.find(n => n.id === nodeId);
      if (node) {
        return { cluster, node };
      }
    }

    // Fallback to load-based selection
    const node = candidateNodes.reduce((best, current) => {
      const bestLoad = best.metrics.performance.connections / 100; // normalized load
      const currentLoad = current.metrics.performance.connections / 100;
      return currentLoad < bestLoad ? current : best;
    });

    return { cluster, node };
  }

  /**
   * Get node for key using consistent hashing
   */
  private getNodeForKey(clusterId: string, key: string): string {
    const ring = this.hashRing.get(clusterId);
    if (!ring) {
      throw new Error(`Hash ring not found for cluster: ${clusterId}`);
    }

    const hash = this.hashKey(key);
    const index = hash % ring.length;
    return ring[index]!;
  }

  /**
   * Hash key for consistent hashing
   */
  private hashKey(key: string): number {
    let hash = 0;
    for (let i = 0; i < key.length; i++) {
      const char = key.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // Convert to 32-bit integer
    }
    return Math.abs(hash);
  }

  /**
   * Update hash ring for cluster
   */
  private updateHashRing(clusterId: string): void {
    const cluster = this.clusters.get(clusterId);
    if (!cluster) return;

    const ring: string[] = [];
    const virtualNodes = 150; // Virtual nodes per physical node

    for (const node of cluster.nodes) {
      if (node.role === 'master') {
        for (let i = 0; i < virtualNodes; i++) {
          ring.push(node.id);
        }
      }
    }

    // Shuffle for better distribution
    for (let i = ring.length - 1; i > 0; i--) {
      const j = Math.floor(Math.random() * (i + 1));
      [ring[i]!, ring[j]!] = [ring[j]!, ring[i]!];
    }

    this.hashRing.set(clusterId, ring);

    logger.debug('Hash ring updated', {
      clusterId,
      ringSize: ring.length,
      physicalNodes: cluster.nodes.filter(n => n.role === 'master').length,
    });
  }

  /**
   * Check circuit breaker status
   */
  private async checkCircuitBreaker(nodeId: string): Promise<void> {
    const breaker = this.circuitBreakers.get(nodeId);
    if (!breaker) return;

    if (breaker.state === 'open') {
      const timeSinceLastFailure = Date.now() - breaker.lastFailure.getTime();
      if (timeSinceLastFailure < 60000) { // 1 minute timeout
        throw new Error(`Circuit breaker is open for node: ${nodeId}`);
      }
      breaker.state = 'half-open';
    }
  }

  /**
   * Execute cache operation on node
   */
  private async executeOperation(
    cluster: CacheCluster,
    node: CacheNode,
    operation: CacheOperation
  ): Promise<any> {
    // Simulate Redis operations
    switch (operation.type) {
      case 'get':
        return this.simulateGet(node, operation.key!);

      case 'set':
        return this.simulateSet(node, operation.key!, operation.value, operation.ttl);

      case 'del':
        return this.simulateDel(node, operation.keys || [operation.key!]);

      case 'exists':
        return this.simulateExists(node, operation.key!);

      case 'expire':
        return this.simulateExpire(node, operation.key!, operation.ttl!);

      case 'ttl':
        return this.simulateTtl(node, operation.key!);

      case 'scan':
        return this.simulateScan(node, operation.pattern!);

      case 'pipeline':
        return this.simulatePipeline(node, operation);

      case 'transaction':
        return this.simulateTransaction(node, operation);

      default:
        throw new Error(`Unsupported operation type: ${operation.type}`);
    }
  }

  /**
   * Simulate Redis GET operation
   */
  private async simulateGet(node: CacheNode, key: string): Promise<any> {
    // Simulate network latency
    await new Promise(resolve => setTimeout(resolve, Math.random() * 10));

    // Simulate cache hit/miss
    const hitProbability = node.metrics.performance.hitRate / 100;
    const isHit = Math.random() < hitProbability;

    if (isHit) {
      this.stats.operations.hits++;
      return {
        key,
        value: `cached_value_${key}`,
        ttl: Math.floor(Math.random() * 3600),
        hit: true,
      };
    } else {
      this.stats.operations.misses++;
      return null;
    }
  }

  /**
   * Simulate Redis SET operation
   */
  private async simulateSet(node: CacheNode, key: string, value: any, ttl?: number): Promise<boolean> {
    // Simulate network latency
    await new Promise(resolve => setTimeout(resolve, Math.random() * 5));

    // Update node metrics
    node.metrics.memory.used += this.estimateSize(value);

    logger.debug('Cache SET operation', {
      nodeId: node.id,
      key,
      ttl,
      valueSize: this.estimateSize(value),
    });

    return true;
  }

  /**
   * Simulate Redis DEL operation
   */
  private async simulateDel(node: CacheNode, keys: string[]): Promise<number> {
    await new Promise(resolve => setTimeout(resolve, Math.random() * 3));

    // Simulate deletion of random subset
    const deletedCount = Math.floor(Math.random() * keys.length);

    logger.debug('Cache DEL operation', {
      nodeId: node.id,
      keysRequested: keys.length,
      deletedCount,
    });

    return deletedCount;
  }

  /**
   * Simulate Redis EXISTS operation
   */
  private async simulateExists(node: CacheNode, key: string): Promise<boolean> {
    await new Promise(resolve => setTimeout(resolve, Math.random() * 2));
    return Math.random() < 0.7; // 70% exist probability
  }

  /**
   * Simulate Redis EXPIRE operation
   */
  private async simulateExpire(node: CacheNode, key: string, ttl: number): Promise<boolean> {
    await new Promise(resolve => setTimeout(resolve, Math.random() * 2));
    return Math.random() < 0.9; // 90% success probability
  }

  /**
   * Simulate Redis TTL operation
   */
  private async simulateTtl(node: CacheNode, key: string): Promise<number> {
    await new Promise(resolve => setTimeout(resolve, Math.random() * 2));
    return Math.floor(Math.random() * 3600); // Random TTL
  }

  /**
   * Simulate Redis SCAN operation
   */
  private async simulateScan(node: CacheNode, pattern: string): Promise<string[]> {
    await new Promise(resolve => setTimeout(resolve, Math.random() * 20));

    // Generate matching keys
    const keys: string[] = [];
    const count = Math.floor(Math.random() * 100);

    for (let i = 0; i < count; i++) {
      keys.push(`${pattern.replace('*', '')}${i}`);
    }

    return keys;
  }

  /**
   * Simulate Redis pipeline operation
   */
  private async simulatePipeline(node: CacheNode, operation: CacheOperation): Promise<any[]> {
    await new Promise(resolve => setTimeout(resolve, Math.random() * 50));

    // Simulate pipeline with multiple operations
    const results = [];
    const opCount = Math.floor(Math.random() * 10) + 1;

    for (let i = 0; i < opCount; i++) {
      results.push(`pipeline_result_${i}`);
    }

    return results;
  }

  /**
   * Simulate Redis transaction
   */
  private async simulateTransaction(node: CacheNode, operation: CacheOperation): Promise<any[]> {
    await new Promise(resolve => setTimeout(resolve, Math.random() * 30));

    // Simulate transaction success/failure
    const success = Math.random() < 0.95; // 95% success rate

    if (success) {
      return ['OK', 'OK', 'OK']; // Successful transaction
    } else {
      throw new Error('Transaction aborted');
    }
  }

  /**
   * Estimate serialized size of value
   */
  private estimateSize(value: any): number {
    try {
      return JSON.stringify(value).length * 2; // Rough estimate
    } catch {
      return 1024; // Default estimate
    }
  }

  /**
   * Find applicable cache policy
   */
  private findApplicablePolicy(operation: CacheOperation): CachePolicy | null {
    if (!operation.key) return null;

    const policies = Array.from(this.policies.values())
      .filter(p => p.enabled)
      .sort((a, b) => b.priority - a.priority);

    for (const policy of policies) {
      const regex = new RegExp(policy.pattern);
      if (regex.test(operation.key)) {
        return policy;
      }
    }

    return null;
  }

  /**
   * Apply cache policy to operation
   */
  private applyPolicy(operation: CacheOperation, policy: CachePolicy): void {
    // Apply TTL rules
    if (operation.type === 'set' && !operation.ttl) {
      operation.ttl = policy.rules.ttl.default;
    }

    // Apply storage rules
    if (policy.rules.storage.compress) {
      operation.options.compress = true;
    }

    if (policy.rules.storage.serialize) {
      operation.options.serialize = true;
    }

    // Apply consistency rules
    operation.options.consistency = policy.rules.replication.consistency;

    // Apply access rules
    if (operation.type === 'get') {
      operation.options.nodePreference = policy.rules.access.readPreference as 'master' | 'replica' | 'any';
    }

    logger.debug('Cache policy applied', {
      operationId: operation.id,
      policyId: policy.id,
      ttl: operation.ttl,
      consistency: operation.options.consistency,
    });
  }

  /**
   * Create cache policy
   */
  createPolicy(policy: Omit<CachePolicy, 'id'>): string {
    const id = stringUtils.random(8);
    this.policies.set(id, { ...policy, id });

    logger.info('Cache policy created', {
      policyId: id,
      name: policy.name,
      pattern: policy.pattern,
      priority: policy.priority,
    });

    monitoring.recordMetric({
      name: 'cache.policy.created',
      value: 1,
      tags: {
        policyName: policy.name,
      },
    });

    return id;
  }

  /**
   * Acquire distributed lock
   */
  async acquireLock(
    key: string,
    owner: string,
    ttl: number = 30000,
    options: {
      autoRenew?: boolean;
      retryAttempts?: number;
      retryDelay?: number;
    } = {}
  ): Promise<string | null> {
    const lockId = stringUtils.random(16);
    const lockKey = `lock:${key}`;

    // Check if lock already exists
    const existingLock = Array.from(this.locks.values()).find(l => l.key === lockKey);
    if (existingLock && existingLock.expires > new Date()) {
      return null; // Lock already held
    }

    const lock: DistributedLock = {
      id: lockId,
      key: lockKey,
      owner,
      ttl,
      acquired: new Date(),
      expires: new Date(Date.now() + ttl),
      renewals: 0,
      autoRenew: options.autoRenew || false,
      metadata: {},
    };

    this.locks.set(lockId, lock);

    logger.debug('Distributed lock acquired', {
      lockId,
      key: lockKey,
      owner,
      ttl,
      autoRenew: lock.autoRenew,
    });

    monitoring.recordMetric({
      name: 'cache.lock.acquired',
      value: 1,
      tags: {
        key: lockKey,
        owner,
      },
    });

    return lockId;
  }

  /**
   * Release distributed lock
   */
  async releaseLock(lockId: string, owner: string): Promise<boolean> {
    const lock = this.locks.get(lockId);
    if (!lock) {
      return false;
    }

    if (lock.owner !== owner) {
      throw new Error('Lock can only be released by its owner');
    }

    this.locks.delete(lockId);

    logger.debug('Distributed lock released', {
      lockId,
      key: lock.key,
      owner,
      duration: Date.now() - lock.acquired.getTime(),
      renewals: lock.renewals,
    });

    monitoring.recordMetric({
      name: 'cache.lock.released',
      value: 1,
      tags: {
        key: lock.key,
        owner,
      },
    });

    return true;
  }

  /**
   * Renew distributed lock
   */
  async renewLock(lockId: string, owner: string, additionalTtl: number = 30000): Promise<boolean> {
    const lock = this.locks.get(lockId);
    if (!lock) {
      return false;
    }

    if (lock.owner !== owner) {
      throw new Error('Lock can only be renewed by its owner');
    }

    lock.expires = new Date(Date.now() + additionalTtl);
    lock.renewals++;

    logger.debug('Distributed lock renewed', {
      lockId,
      key: lock.key,
      owner,
      newExpires: lock.expires,
      renewalCount: lock.renewals,
    });

    return true;
  }

  /**
   * Update operation statistics
   */
  private updateStats(operation: CacheOperation, duration: number, success: boolean): void {
    this.stats.operations.total++;

    switch (operation.type) {
      case 'get':
        this.stats.operations.gets++;
        break;
      case 'set':
        this.stats.operations.sets++;
        break;
      case 'del':
        this.stats.operations.dels++;
        break;
    }

    // Update performance metrics
    this.stats.performance.avgLatency =
      (this.stats.performance.avgLatency + duration) / 2;

    // Update hit rate for GET operations
    if (operation.type === 'get') {
      this.stats.operations.hitRate =
        (this.stats.operations.hits / this.stats.operations.gets) * 100;
    }

    // Update throughput (operations per second)
    this.stats.performance.throughput = this.stats.operations.total / 60; // rough calculation
  }

  /**
   * Setup default cluster
   */
  private setupDefaultCluster(): void {
    const nodes: CacheNode[] = [
      {
        id: 'node-master-1',
        host: 'localhost',
        port: 7000,
        role: 'master',
        status: 'connected',
        slots: Array.from({ length: 5461 }, (_, i) => i), // 0-5460
        replicas: ['node-replica-1'],
        metrics: {
          memory: { used: 50 * 1024 * 1024, max: 1024 * 1024 * 1024, percentage: 5 },
          performance: { connections: 10, opsPerSecond: 1000, hitRate: 85, avgLatency: 2 },
          replication: { lag: 0, backlog: 0, syncInProgress: false },
        },
        lastPing: new Date(),
        version: '7.0.0',
      },
      {
        id: 'node-master-2',
        host: 'localhost',
        port: 7001,
        role: 'master',
        status: 'connected',
        slots: Array.from({ length: 5461 }, (_, i) => i + 5461), // 5461-10921
        replicas: ['node-replica-2'],
        metrics: {
          memory: { used: 45 * 1024 * 1024, max: 1024 * 1024 * 1024, percentage: 4.5 },
          performance: { connections: 8, opsPerSecond: 950, hitRate: 87, avgLatency: 1.8 },
          replication: { lag: 0, backlog: 0, syncInProgress: false },
        },
        lastPing: new Date(),
        version: '7.0.0',
      },
      {
        id: 'node-master-3',
        host: 'localhost',
        port: 7002,
        role: 'master',
        status: 'connected',
        slots: Array.from({ length: 5462 }, (_, i) => i + 10922), // 10922-16383
        replicas: ['node-replica-3'],
        metrics: {
          memory: { used: 52 * 1024 * 1024, max: 1024 * 1024 * 1024, percentage: 5.2 },
          performance: { connections: 12, opsPerSecond: 1100, hitRate: 83, avgLatency: 2.2 },
          replication: { lag: 0, backlog: 0, syncInProgress: false },
        },
        lastPing: new Date(),
        version: '7.0.0',
      },
      // Replica nodes
      {
        id: 'node-replica-1',
        host: 'localhost',
        port: 7003,
        role: 'replica',
        status: 'connected',
        slots: [],
        replicas: [],
        metrics: {
          memory: { used: 50 * 1024 * 1024, max: 1024 * 1024 * 1024, percentage: 5 },
          performance: { connections: 5, opsPerSecond: 500, hitRate: 85, avgLatency: 2.1 },
          replication: { lag: 100, backlog: 1024, syncInProgress: false },
        },
        lastPing: new Date(),
        version: '7.0.0',
      },
      {
        id: 'node-replica-2',
        host: 'localhost',
        port: 7004,
        role: 'replica',
        status: 'connected',
        slots: [],
        replicas: [],
        metrics: {
          memory: { used: 45 * 1024 * 1024, max: 1024 * 1024 * 1024, percentage: 4.5 },
          performance: { connections: 4, opsPerSecond: 480, hitRate: 87, avgLatency: 1.9 },
          replication: { lag: 80, backlog: 512, syncInProgress: false },
        },
        lastPing: new Date(),
        version: '7.0.0',
      },
      {
        id: 'node-replica-3',
        host: 'localhost',
        port: 7005,
        role: 'replica',
        status: 'connected',
        slots: [],
        replicas: [],
        metrics: {
          memory: { used: 52 * 1024 * 1024, max: 1024 * 1024 * 1024, percentage: 5.2 },
          performance: { connections: 6, opsPerSecond: 520, hitRate: 83, avgLatency: 2.3 },
          replication: { lag: 120, backlog: 2048, syncInProgress: false },
        },
        lastPing: new Date(),
        version: '7.0.0',
      },
    ];

    this.createCluster({
      name: 'Main Redis Cluster',
      nodes,
      configuration: {
        replicationFactor: 1,
        shardCount: 3,
        maxMemoryPolicy: 'allkeys-lru',
        persistence: {
          enabled: true,
          type: 'both',
          schedule: '0 2 * * *', // Daily at 2 AM
        },
        security: {
          auth: true,
          tls: true,
          aclEnabled: true,
          password: 'cluster-password',
        },
        networking: {
          timeout: 5000,
          keepAlive: 30,
          maxConnections: 1000,
          cluster: {
            enabled: true,
            nodeTimeout: 15000,
            requireFullCoverage: true,
          },
        },
      },
    });

    logger.info('Default Redis cluster created');
  }

  /**
   * Setup default cache policies
   */
  private setupDefaultPolicies(): void {
    // Session cache policy
    this.createPolicy({
      name: 'Session Cache',
      pattern: 'session:*',
      rules: {
        ttl: {
          default: 1800, // 30 minutes
          min: 300,
          max: 7200,
          sliding: true,
        },
        eviction: {
          policy: 'lru',
          priority: 10,
        },
        storage: {
          compress: false,
          serialize: true,
          partition: 'sessions',
        },
        replication: {
          factor: 2,
          consistency: 'eventual',
        },
        access: {
          readPreference: 'master',
          writePolicy: 'write-through',
        },
      },
      conditions: {
        keySize: { max: 1024 },
        valueSize: { max: 64 * 1024 },
      },
      enabled: true,
      priority: 10,
    });

    // API Response cache policy
    this.createPolicy({
      name: 'API Response Cache',
      pattern: 'api:*',
      rules: {
        ttl: {
          default: 300, // 5 minutes
          min: 60,
          max: 3600,
        },
        eviction: {
          policy: 'lfu',
          priority: 8,
        },
        storage: {
          compress: true,
          serialize: true,
          partition: 'api-responses',
        },
        replication: {
          factor: 1,
          consistency: 'eventual',
        },
        access: {
          readPreference: 'replica',
          writePolicy: 'write-through',
        },
      },
      conditions: {
        valueSize: { min: 1024 }, // Only cache larger responses
        hitRate: { min: 50 }, // Minimum 50% hit rate
      },
      enabled: true,
      priority: 8,
    });

    // Analytics cache policy
    this.createPolicy({
      name: 'Analytics Cache',
      pattern: 'analytics:*',
      rules: {
        ttl: {
          default: 3600, // 1 hour
          min: 600,
          max: 86400,
        },
        eviction: {
          policy: 'ttl',
          priority: 5,
        },
        storage: {
          compress: true,
          serialize: true,
          partition: 'analytics',
        },
        replication: {
          factor: 2,
          consistency: 'strong',
        },
        access: {
          readPreference: 'master',
          writePolicy: 'write-back',
        },
      },
      conditions: {
        accessFrequency: { min: 10, period: 3600 },
      },
      enabled: true,
      priority: 5,
    });

    logger.info('Default cache policies created');
  }

  /**
   * Start health monitoring
   */
  private startHealthMonitoring(): void {
    setInterval(async () => {
      for (const [clusterId, cluster] of this.clusters.entries()) {
        let healthyNodes = 0;
        let totalMemory = 0;
        let usedMemory = 0;
        let totalConnections = 0;

        for (const node of cluster.nodes) {
          try {
            // Simulate health check
            const isHealthy = Math.random() > 0.05; // 95% uptime
            node.status = isHealthy ? 'connected' : 'error';
            node.lastPing = new Date();

            if (isHealthy) {
              healthyNodes++;

              // Update node metrics
              node.metrics.memory.used += Math.floor((Math.random() - 0.5) * 1024 * 1024);
              node.metrics.memory.used = Math.max(0, node.metrics.memory.used);
              node.metrics.memory.percentage =
                (node.metrics.memory.used / node.metrics.memory.max) * 100;

              node.metrics.performance.connections += Math.floor((Math.random() - 0.5) * 5);
              node.metrics.performance.connections = Math.max(0, node.metrics.performance.connections);

              node.metrics.performance.opsPerSecond =
                800 + Math.floor(Math.random() * 400);

              node.metrics.performance.hitRate =
                80 + Math.random() * 15;

              node.metrics.performance.avgLatency =
                1 + Math.random() * 3;

              // Update replication metrics for replicas
              if (node.role === 'replica') {
                node.metrics.replication.lag = Math.floor(Math.random() * 200);
                node.metrics.replication.backlog = Math.floor(Math.random() * 4096);
              }

              totalMemory += node.metrics.memory.max;
              usedMemory += node.metrics.memory.used;
              totalConnections += node.metrics.performance.connections;

              // Reset circuit breaker on successful health check
              const breaker = this.circuitBreakers.get(node.id);
              if (breaker && breaker.state !== 'closed') {
                breaker.failures = 0;
                breaker.state = 'closed';
              }

            } else {
              // Update circuit breaker on failure
              const breaker = this.circuitBreakers.get(node.id);
              if (breaker) {
                breaker.failures++;
                breaker.lastFailure = new Date();
                if (breaker.failures >= 5) {
                  breaker.state = 'open';
                }
              }
            }

            monitoring.recordMetric({
              name: 'cache.node.health',
              value: isHealthy ? 1 : 0,
              tags: {
                clusterId,
                nodeId: node.id,
                role: node.role,
              },
            });

            monitoring.recordMetric({
              name: 'cache.node.memory.usage',
              value: node.metrics.memory.percentage,
              tags: {
                clusterId,
                nodeId: node.id,
              },
              unit: 'percent',
            });

            monitoring.recordMetric({
              name: 'cache.node.connections',
              value: node.metrics.performance.connections,
              tags: {
                clusterId,
                nodeId: node.id,
              },
            });

          } catch (error) {
            node.status = 'error';
            logger.error('Node health check failed', {
              clusterId,
              nodeId: node.id,
              error: String(error),
            });
          }
        }

        // Update cluster status
        const healthPercentage = (healthyNodes / cluster.nodes.length) * 100;
        if (healthPercentage >= 90) {
          cluster.status = 'healthy';
        } else if (healthPercentage >= 60) {
          cluster.status = 'degraded';
        } else {
          cluster.status = 'offline';
        }

        // Update cluster metrics
        cluster.metrics.totalMemory = totalMemory;
        cluster.metrics.usedMemory = usedMemory;
        cluster.metrics.totalConnections = totalConnections;

        const avgHitRate = cluster.nodes
          .filter(n => n.status === 'connected')
          .reduce((sum, n) => sum + n.metrics.performance.hitRate, 0) / healthyNodes || 0;
        cluster.metrics.avgHitRate = avgHitRate;

        const avgLatency = cluster.nodes
          .filter(n => n.status === 'connected')
          .reduce((sum, n) => sum + n.metrics.performance.avgLatency, 0) / healthyNodes || 0;
        cluster.metrics.avgLatency = avgLatency;

        monitoring.recordMetric({
          name: 'cache.cluster.health',
          value: healthPercentage,
          tags: {
            clusterId,
            clusterName: cluster.name,
          },
          unit: 'percent',
        });

        // Update hash ring if cluster topology changed
        const masterNodes = cluster.nodes.filter(n => n.role === 'master' && n.status === 'connected');
        if (masterNodes.length !== (this.hashRing.get(clusterId)?.length || 0) / 150) {
          this.updateHashRing(clusterId);
        }
      }
    }, 30000); // Every 30 seconds
  }

  /**
   * Start performance tracking
   */
  private startPerformanceTracking(): void {
    setInterval(() => {
      // Update global statistics
      const allClusters = Array.from(this.clusters.values());
      const healthyClusters = allClusters.filter(c => c.status === 'healthy');

      if (healthyClusters.length > 0) {
        this.stats.memory.used = healthyClusters.reduce((sum, c) => sum + c.metrics.usedMemory, 0);
        this.stats.memory.available = healthyClusters.reduce((sum, c) => sum + c.metrics.totalMemory, 0) - this.stats.memory.used;
        this.stats.connections.active = healthyClusters.reduce((sum, c) => sum + c.metrics.totalConnections, 0);

        // Calculate average performance metrics
        this.stats.performance.avgLatency =
          healthyClusters.reduce((sum, c) => sum + c.metrics.avgLatency, 0) / healthyClusters.length;
      }

      // Record global metrics
      monitoring.recordMetric({
        name: 'cache.global.memory.used',
        value: this.stats.memory.used,
        tags: {},
        unit: 'bytes',
      });

      monitoring.recordMetric({
        name: 'cache.global.operations.total',
        value: this.stats.operations.total,
        tags: {},
      });

      monitoring.recordMetric({
        name: 'cache.global.hit_rate',
        value: this.stats.operations.hitRate,
        tags: {},
        unit: 'percent',
      });

      monitoring.recordMetric({
        name: 'cache.global.latency.avg',
        value: this.stats.performance.avgLatency,
        tags: {},
        unit: 'ms',
      });

    }, 60000); // Every minute
  }

  /**
   * Start replication monitoring
   */
  private startReplicationMonitoring(): void {
    setInterval(() => {
      for (const [clusterId, cluster] of this.clusters.entries()) {
        const replicas = cluster.nodes.filter(n => n.role === 'replica');
        let syncedReplicas = 0;
        let totalLag = 0;
        let maxLag = 0;

        for (const replica of replicas) {
          const lag = replica.metrics.replication.lag;
          totalLag += lag;
          maxLag = Math.max(maxLag, lag);

          if (lag < 1000 && !replica.metrics.replication.syncInProgress) {
            syncedReplicas++;
          }

          monitoring.recordMetric({
            name: 'cache.replication.lag',
            value: lag,
            tags: {
              clusterId,
              nodeId: replica.id,
            },
            unit: 'ms',
          });
        }

        // Update replication statistics
        this.stats.replication.syncedNodes = syncedReplicas;
        this.stats.replication.lagAvg = replicas.length > 0 ? totalLag / replicas.length : 0;
        this.stats.replication.lagMax = maxLag;

        monitoring.recordMetric({
          name: 'cache.replication.synced_nodes',
          value: syncedReplicas,
          tags: { clusterId },
        });

        monitoring.recordMetric({
          name: 'cache.replication.lag.avg',
          value: this.stats.replication.lagAvg,
          tags: { clusterId },
          unit: 'ms',
        });
      }
    }, 15000); // Every 15 seconds
  }

  /**
   * Start lock maintenance
   */
  private startLockMaintenance(): void {
    setInterval(() => {
      const now = new Date();
      let expiredLocks = 0;
      let renewedLocks = 0;

      for (const [lockId, lock] of this.locks.entries()) {
        if (lock.expires <= now) {
          // Lock has expired
          this.locks.delete(lockId);
          expiredLocks++;

          logger.debug('Distributed lock expired', {
            lockId,
            key: lock.key,
            owner: lock.owner,
            duration: now.getTime() - lock.acquired.getTime(),
          });

        } else if (lock.autoRenew && lock.expires.getTime() - now.getTime() < lock.ttl * 0.2) {
          // Auto-renew lock if less than 20% TTL remaining
          lock.expires = new Date(now.getTime() + lock.ttl);
          lock.renewals++;
          renewedLocks++;

          logger.debug('Distributed lock auto-renewed', {
            lockId,
            key: lock.key,
            owner: lock.owner,
            newExpires: lock.expires,
            renewalCount: lock.renewals,
          });
        }
      }

      if (expiredLocks > 0) {
        monitoring.recordMetric({
          name: 'cache.locks.expired',
          value: expiredLocks,
          tags: {},
        });
      }

      if (renewedLocks > 0) {
        monitoring.recordMetric({
          name: 'cache.locks.renewed',
          value: renewedLocks,
          tags: {},
        });
      }

      monitoring.recordMetric({
        name: 'cache.locks.active',
        value: this.locks.size,
        tags: {},
      });

    }, 10000); // Every 10 seconds
  }

  /**
   * Get cache statistics
   */
  getCacheStatistics(): CacheStats {
    return { ...this.stats };
  }

  /**
   * Get cluster details
   */
  getCluster(clusterId: string): CacheCluster | undefined {
    return this.clusters.get(clusterId);
  }

  /**
   * Get node details
   */
  getNode(nodeId: string): CacheNode | undefined {
    return this.nodes.get(nodeId);
  }

  /**
   * Get policy details
   */
  getPolicy(policyId: string): CachePolicy | undefined {
    return this.policies.get(policyId);
  }

  /**
   * List active locks
   */
  getActiveLocks(): DistributedLock[] {
    const now = new Date();
    return Array.from(this.locks.values()).filter(lock => lock.expires > now);
  }

  /**
   * Get cluster topology
   */
  getClusterTopology(): {
    clusters: number;
    nodes: { total: number; masters: number; replicas: number; sentinels: number };
    health: { healthy: number; degraded: number; offline: number };
    shards: number;
    slots: number;
  } {
    const clusters = Array.from(this.clusters.values());
    const allNodes = Array.from(this.nodes.values());

    const topology = {
      clusters: clusters.length,
      nodes: {
        total: allNodes.length,
        masters: allNodes.filter(n => n.role === 'master').length,
        replicas: allNodes.filter(n => n.role === 'replica').length,
        sentinels: allNodes.filter(n => n.role === 'sentinel').length,
      },
      health: {
        healthy: clusters.filter(c => c.status === 'healthy').length,
        degraded: clusters.filter(c => c.status === 'degraded').length,
        offline: clusters.filter(c => c.status === 'offline').length,
      },
      shards: clusters.reduce((sum, c) => sum + c.configuration.shardCount, 0),
      slots: 16384, // Redis cluster total slots
    };

    return topology;
  }
}

// Export singleton instance
export const redisClusterManager = new RedisClusterManager();
